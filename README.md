# LlamaIndex Project

This is a [LlamaIndex](https://www.llamaindex.ai/) project bootstrapped with [`create-llama`](https://github.com/run-llama/LlamaIndexTS/tree/main/packages/create-llama).

## Getting Started

This project consists of a frontend and a backend. 

### Frontend

The frontend is a [Next.js](https://nextjs.org/) application. To get started with the frontend, follow the instructions in the [frontend README](./frontend/README.md).

### Backend

The backend is a [FastAPI](https://fastapi.tiangolo.com/) application. To get started with the backend, follow the instructions in the [backend README](./backend/README.md).

Once both the frontend and backend servers are running, open [http://localhost:3000](http://localhost:3000) with your browser to see the result.

## Learn More

To learn more about LlamaIndex, take a look at the following resources:


You can check out [the LlamaIndexTS GitHub repository](https://github.com/run-llama/LlamaIndexTS) - your feedback and contributions are welcome!
